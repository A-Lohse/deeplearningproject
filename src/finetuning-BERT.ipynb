{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score, average_precision_score \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler, DataCollatorWithPadding\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "os.chdir(\"C:/Users/espen/Documents/SDS/deeplearningproject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_rename_columns(path:str, rename_dict={}, drop_columns_dict={}, drop_congress_number=[])->pd.DataFrame:\n",
    "    #load data\n",
    "    df = pd.read_pickle(path)\n",
    "    df = df.loc[~df['cong'].isin(drop_congress_number)].copy()\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    df = df.drop(columns=drop_columns_dict)\n",
    "    return df\n",
    "    \n",
    "def train_validation_split(df, train_frac,eval_frac,random_seed):\n",
    "    df_train = df.sample(frac=train_frac, random_state=random_seed)\n",
    "    df_eval = df.sample(frac=eval_frac, random_state=random_seed)\n",
    "    return df_train, df_eval\n",
    "\n",
    "def create_dataset_object_from_pandas_dataframe(df,columns_to_be_removed):\n",
    "    dataset = datasets.Dataset.from_pandas(df).remove_columns(columns_to_be_removed)\n",
    "    return dataset\n",
    "\n",
    "def tokenizer_function(bill):\n",
    "    return tokenizer(bill[\"sentences\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "def create_weighted_sampler(dataset):\n",
    "    class_sample_count = np.array([len(np.where(dataset[\"labels\"] == t)[0]) for t in np.unique(dataset[\"labels\"])])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in dataset[\"labels\"]])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weight = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, eval_dataloader, loss_function, optimizer, num_epochs, lr_scheduler_function, device):\n",
    "    \n",
    "\n",
    "    model.train().to(device)\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    lr_scheduler = get_scheduler(\n",
    "        lr_scheduler_function,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_training_steps/10,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        train_targs, train_preds = [], []\n",
    "        val_targs, val_preds = [], []\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_function(outputs.logits, batch[\"labels\"])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)            \n",
    "\n",
    "            #Getting metrics\n",
    "            train_targs += list(batch[\"labels\"].cpu().numpy())\n",
    "            train_preds += list(predictions.cpu().numpy())\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        \n",
    "        print('-----------Training Metrics-----------')\n",
    "        print('Accuracy: {}'.format(accuracy_score(train_targs, train_preds)))\n",
    "        print('F1: {}'.format(f1_score(train_targs, train_preds)))\n",
    "        print('Precision: {}'.format(precision_score(train_targs, train_preds)))\n",
    "        print('Recall: {}'.format(recall_score(train_targs, train_preds)))\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(train_targs, train_preds))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():   \n",
    "            for batch in eval_dataloader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=-1)            \n",
    "\n",
    "                #Getting metrics\n",
    "                val_targs += list(batch[\"labels\"].cpu().numpy())\n",
    "                val_preds += list(predictions.cpu().numpy())\n",
    "\n",
    "        print('-----------Validation Metrics-----------')\n",
    "        print('Accuracy: {}'.format(accuracy_score(val_targs, val_preds)))\n",
    "        print('F1: {}'.format(f1_score(val_targs, val_preds)))\n",
    "        print('Precision: {}'.format(precision_score(val_targs, val_preds)))\n",
    "        print('Recall: {}'.format(recall_score(val_targs, val_preds)))\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(val_targs, val_preds))\n",
    "        print('-' * 66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Combining list of sentences with [SEP] tokens...\n",
      "Training validation split...\n",
      "Converting pandas df to dataset-object...\n",
      "Loading tokenizer...\n",
      "Applying tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:10<00:00,  1.57ba/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.73ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloader with batches using a weighted sampler\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2760/11040 [24:26<1:13:20,  1.88it/s, loss=0.00742] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training Metrics-----------\n",
      "Accuracy: 0.8270531400966183\n",
      "F1: 0.8297467601949827\n",
      "Precision: 0.8125509372453138\n",
      "Recall: 0.8476861411393174\n",
      "Confusion Matrix:\n",
      "[[6717 1610]\n",
      " [1254 6979]]\n",
      "-----------Validation Metrics-----------\n",
      "Accuracy: 0.9647342995169083\n",
      "F1: 0.6490384615384615\n",
      "Precision: 0.48736462093862815\n",
      "Recall: 0.9712230215827338\n",
      "Confusion Matrix:\n",
      "[[3859  142]\n",
      " [   4  135]]\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5520/11040 [50:06<47:23,  1.94it/s, loss=0.579]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training Metrics-----------\n",
      "Accuracy: 0.9798913043478261\n",
      "F1: 0.9799554565701558\n",
      "Precision: 0.9759021700035967\n",
      "Recall: 0.9840425531914894\n",
      "Confusion Matrix:\n",
      "[[8087  201]\n",
      " [ 132 8140]]\n",
      "-----------Validation Metrics-----------\n",
      "Accuracy: 0.9881642512077294\n",
      "F1: 0.8492307692307692\n",
      "Precision: 0.7419354838709677\n",
      "Recall: 0.9928057553956835\n",
      "Confusion Matrix:\n",
      "[[3953   48]\n",
      " [   1  138]]\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 8280/11040 [1:15:46<23:37,  1.95it/s, loss=0.000563]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training Metrics-----------\n",
      "Accuracy: 0.9914251207729469\n",
      "F1: 0.9913719771539676\n",
      "Precision: 0.9912515188335358\n",
      "Recall: 0.9914924647544968\n",
      "Confusion Matrix:\n",
      "[[8260   72]\n",
      " [  70 8158]]\n",
      "-----------Validation Metrics-----------\n",
      "Accuracy: 0.9958937198067633\n",
      "F1: 0.9423728813559323\n",
      "Precision: 0.8910256410256411\n",
      "Recall: 1.0\n",
      "Confusion Matrix:\n",
      "[[3984   17]\n",
      " [   0  139]]\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11040/11040 [1:41:25<00:00,  1.94it/s, loss=0.00025]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training Metrics-----------\n",
      "Accuracy: 0.9982487922705314\n",
      "F1: 0.9982305204710477\n",
      "Precision: 0.997317727383565\n",
      "Recall: 0.9991449859533407\n",
      "Confusion Matrix:\n",
      "[[8351   22]\n",
      " [   7 8180]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11040/11040 [1:43:23<00:00,  1.78it/s, loss=0.00025]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Validation Metrics-----------\n",
      "Accuracy: 0.9992753623188406\n",
      "F1: 0.9893238434163701\n",
      "Precision: 0.9788732394366197\n",
      "Recall: 1.0\n",
      "Confusion Matrix:\n",
      "[[3998    3]\n",
      " [   0  139]]\n",
      "------------------------------------------------------------------\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "df = load_data_and_rename_columns('data/processed/bert_data.pickle',\n",
    "            rename_dict={\"status\":\"labels\"},\n",
    "            drop_columns_dict={'bill_id','cong'},\n",
    "            drop_congress_number=[115])\n",
    "\n",
    "print(\"Combining list of sentences with [SEP] tokens...\")\n",
    "df['sentences'] = df['sentences'].apply(lambda x: '[SEP] '.join(x))\n",
    "\n",
    "print(\"Training validation split...\")\n",
    "df_train, df_eval = train_validation_split(df, 0.8, 0.2, random_seed=3060)\n",
    "# class_weights = list(float(x) for x in compute_class_weight('balanced', classes=df_train[\"labels\"].unique(), y=df_train[\"labels\"]))\n",
    "\n",
    "print(\"Converting pandas df to dataset-object...\")\n",
    "dataset_train = create_dataset_object_from_pandas_dataframe(df_train, \"__index_level_0__\")\n",
    "dataset_eval = create_dataset_object_from_pandas_dataframe(df_eval, \"__index_level_0__\")\n",
    "dataset = datasets.DatasetDict({\"train\":dataset_train,\"eval\":dataset_eval})\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "print(\"Applying tokenizer\")\n",
    "dataset_tokenized = dataset.map(tokenizer_function, batched=True)\n",
    "dataset_tokenized[\"train\"] = dataset_tokenized[\"train\"].remove_columns(\"sentences\")\n",
    "dataset_tokenized[\"eval\"] = dataset_tokenized[\"eval\"].remove_columns(\"sentences\")\n",
    "dataset_tokenized.set_format(\"torch\") #converting lists to tensors\n",
    "\n",
    "print(\"Creating dataloader with batches using a weighted sampler\")\n",
    "sampler = create_weighted_sampler(dataset_tokenized[\"train\"])\n",
    "train_dataloader = DataLoader(dataset_tokenized[\"train\"], batch_size=6, drop_last=True, sampler=sampler)\n",
    "eval_dataloader = DataLoader(dataset_tokenized[\"eval\"], batch_size=6, drop_last = True)\n",
    "\n",
    "print(\"Loading model\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "print(\"Training model\")\n",
    "#Arguments:\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "num_epochs = 4\n",
    "lr_scheduler_function = \"linear\"\n",
    "# class_weights = torch.tensor(device=device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Training function\n",
    "train(model, train_dataloader, eval_dataloader,loss_function, optimizer, num_epochs, lr_scheduler_function, device)\n",
    "\n",
    "print(\"Saving model\")\n",
    "torch.save(model, \"results/BERT_finetuned_congress_103_114_4_epochs_80pct_train_20_val.pt\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fine-tuned model on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Combining list of sentences with [SEP] tokens...\n",
      "Converting pandas df to dataset-object...\n",
      "Loading tokenizer...\n",
      "Applying tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.87ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloader\n",
      "Calculating predictions of the voting behaviour of the 115th congress\n",
      "-----------Test Metrics-----------\n",
      "Accuracy: 0.9666666666666667\n",
      "F1: 0.25396825396825395\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.14814814814814814\n",
      "AUC 0.5737053425106523\n",
      "Avg. precision 0.1643113562735312\n",
      "Confusion Matrix:\n",
      "[[1355    1]\n",
      " [  46    8]]\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print(\"Loading model\")\n",
    "#model = torch.load(\"results/BERT_finetuned_congress_103_114_4_epochs_80pct_train_20_val.pt\")\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = load_data_and_rename_columns('data/processed/bert_data.pickle',\n",
    "            rename_dict={\"status\":\"labels\"},\n",
    "            drop_columns_dict={'bill_id','cong'},\n",
    "            drop_congress_number=list(range(103,115)))\n",
    "\n",
    "print(\"Combining list of sentences with [SEP] tokens...\")\n",
    "df['sentences'] = df['sentences'].apply(lambda x: '[SEP] '.join(x))\n",
    "\n",
    "print(\"Converting pandas df to dataset-object...\")\n",
    "dataset_test = create_dataset_object_from_pandas_dataframe(df, \"__index_level_0__\")\n",
    "dataset_test = datasets.DatasetDict({\"test\":dataset_test})\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "print(\"Applying tokenizer\")\n",
    "dataset_test_tokenized = dataset_test.map(tokenizer_function, batched=True)\n",
    "dataset_test_tokenized[\"test\"] = dataset_test_tokenized[\"test\"].remove_columns(\"sentences\")\n",
    "dataset_test_tokenized.set_format(\"torch\") #converting lists to tensors\n",
    "\n",
    "print(\"Creating dataloader\")\n",
    "test_dataloader = DataLoader(dataset_test_tokenized[\"test\"], batch_size=6, drop_last=True)\n",
    "\n",
    "test_targs, test_preds = [], []\n",
    "\n",
    "\n",
    "print(\"Calculating predictions of the voting behaviour of the 115th congress\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") \n",
    "with torch.no_grad():   \n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)            \n",
    "\n",
    "        #Getting metrics\n",
    "        test_targs += list(batch[\"labels\"].cpu().numpy())\n",
    "        test_preds += list(predictions.cpu().numpy())\n",
    "\n",
    "    print('-----------Test Metrics-----------')\n",
    "    print('Accuracy: {}'.format(accuracy_score(test_targs, test_preds)))\n",
    "    print('F1: {}'.format(f1_score(test_targs, test_preds)))\n",
    "    print('Precision: {}'.format(precision_score(test_targs, test_preds)))\n",
    "    print('Recall: {}'.format(recall_score(test_targs, test_preds)))\n",
    "    print('AUC {}'.format(roc_auc_score(test_targs, test_preds)))\n",
    "    print('Avg. precision {}'.format(average_precision_score(test_targs, test_preds)))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(test_targs, test_preds))\n",
    "    print('-' * 66)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66f56bbc43aa217dde88ff9dc40ab7d7c7e79ce1d561fbdc90d3a27ed8c9354a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('deeplearning-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
